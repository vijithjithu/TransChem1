CV_flag: True                                     # whether to use cross-validation
LLRD_flag: False                                    # whether to use layer-wise lr decay
aug_flag: False                                  # whether to apply data augmentation
model_indicator: 'pretrain'                        # whether to use pretrained model
aug_indicator:                                  # number of augmentation per SMILES. If no limitation, assign the indicator with None (leave it blank).




dataset_file: '../data/Nc/nc_rfe.csv'                     # test file path if cross-validation is not used
model_path: '../ckpt/pretrain.pt'                      # pretrain model path
save_path: '../ckpt/Nc+cheminfo/Nc_train.pt'                     # checkpoint path
best_model_path: '../ckpt/Nc+cheminfo/Nc_best_model.pt'          # best model save path


normalize: True
fold_seed: [1]
test_size: 0.2 
k: 5                                                # k-fold cross-validation
blocksize: 150                                 # max length of sequences after tokenization
batch_size: 16                                       # batch size
num_epochs: 40                       # total number of epochs
warmup_ratio: 0.1                                  # warmup ratio
drop_rate: 0.3                               # dropout
lr_rate: 0.0001                     # initial lr for LLRD and pretrained cd model lr otherwise
lr_rate_reg:  0.007                          # regressor lr if LLRD is not used
weight_decay: 7.7e-05

hidden_dropout_prob: 0.1                            # hidden layer dropout
attention_probs_dropout_prob: 0.1                   # attention dropout
tolerance: 10                                  # tolerance of no improvement in performance before early stop
num_workers: 8                                      # number of workers when loading data
